{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "p = re.compile(\"[a-z]+\")\n",
    "m = p.search(\"5 python\")\n",
    "m.start() + m.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', '', 'world', '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split(r\"|W\",\"Hello,world!\")\n",
    "['Hello','','world','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 81), ('and', 39), ('href', 37), ('in', 33), ('li', 31), ('i', 27), ('networks', 21), ('http', 20), ('of', 18), ('D', 18)]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, re\n",
    "from collections import Counter\n",
    "url=\"http://www.networksciencelab.com\"\n",
    "\n",
    "pattern=re.compile(r\"\\w+\")\n",
    "try:\n",
    "    page=urllib.request.urlopen(url)\n",
    "except:\n",
    "    print(f\"Cannot open {url}\")\n",
    "    exit()\n",
    "doc=page.read().decode()\n",
    "m=pattern.findall(doc)\n",
    "cntr=Counter(m)\n",
    "cntrdict=cntr.most_common(10)\n",
    "print(cntrdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 81), ('and', 39), ('href', 37), ('in', 33), ('li', 31), ('i', 27), ('networks', 21), ('http', 20), ('of', 18), ('D', 18), ('Zinoviev', 15), ('https', 12), ('to', 12), ('www', 12), ('org', 12), ('class', 11), ('com', 11), ('The', 11), ('table', 10), ('h3', 10), ('the', 10), ('Networks', 9), ('ul', 8), ('Social', 8), ('p', 7), ('book', 7), ('data', 7), ('as', 7), ('with', 7), ('net', 7)]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, re\n",
    "from collections import Counter\n",
    "url=\"http://www.networksciencelab.com\"\n",
    "\n",
    "\n",
    "try:\n",
    "    page=urllib.request.urlopen(url)\n",
    "except:\n",
    "    print(f\"Cannot open {url}\")\n",
    "    exit()\n",
    "doc=page.read().decode()\n",
    "pattern=re.compile(r\"\\w+\")\n",
    "words=pattern.findall(doc)\n",
    "print(Counter(words).most_common(30))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chapter1\\\\Chapter1_text1.txt', 'Chapter1\\\\Chapter1_text2.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob('Chapter1/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chapter1\\\\Chapter1_text1.txt', 'chapter1\\\\Chapter1_text2.txt']\n",
      "{'apple': ['Chapter1_text1.txt'], 'boat': ['Chapter1_text1.txt', ['Chapter1_text2.txt']], 'cola': ['Chapter1_text1.txt'], 'danger': ['Chapter1_text1.txt', ['Chapter1_text2.txt']], 'eagle': ['Chapter1_text2.txt'], 'float': ['Chapter1_text2.txt'], 'game': ['Chapter1_text2.txt']}\n",
      " \n",
      "{'apple': ['Chapter1_text1.txt'], 'boat': ['Chapter1_text1.txt', ['Chapter1_text2.txt']], 'cola': ['Chapter1_text1.txt'], 'danger': ['Chapter1_text1.txt', ['Chapter1_text2.txt']], 'eagle': ['Chapter1_text2.txt'], 'float': ['Chapter1_text2.txt'], 'game': ['Chapter1_text2.txt']}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "text_list=glob.glob('chapter1/*.txt')\n",
    "dict={}\n",
    "print(text_list)\n",
    "for i in text_list:\n",
    "    with open(i) as txt:\n",
    "        for row in txt.readlines():\n",
    "            if row.strip() in dict.keys():\n",
    "                dict[row.strip()].append([i.split('\\\\')[-1]])\n",
    "            else:\n",
    "                dict[row.strip()]=[i.split('\\\\')[-1]]\n",
    "\n",
    "print(dict)\n",
    "with open(\"mydata.pickle\",'wb') as oFile:\n",
    "    pickle.dump(dict,oFile)\n",
    "print(' ')\n",
    "with open(\"mydata.pickle\",'rb') as iFile:\n",
    "    dict1=pickle.load(iFile)\n",
    "    print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['010-9999-9988', '010-9909-7789', '010-8789-7768', '02-1234-5678', '031-123-5678']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern1=re.compile(\"\\d{2,3}-\\d{3,4}-\\d{4}\")\n",
    "list1=[]\n",
    "with open(\"chapter1/phone_number.txt\") as file:\n",
    "    for row in file.readlines():\n",
    "        list1.extend(pattern1.findall(row))\n",
    "print(list1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "My Little Network Science Lab\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "My Little Network Science Lab\n",
      "By Dmitry Zinoviev\n",
      "\n",
      "Books\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I am excited to announce my books, \"Data Science Essentials in Python. Collect →  Organize →  Explore →  Predict →  Value\" (a.k.a. DZPYDS) and \"Complex Network Analysis in Python. Recognize → Construct → Visualize → Analyze → Interpret\" (a.k.a. DZCNAPY), published by the Pragmatic Bookshelf.\n",
      "\n",
      "The first book is intended for seasoned data scientists and statisticians migrating from R to Python, as well as for beginners willing to learn elements of data science in Python.\n",
      "\n",
      "The book leads you from messy, unstructured artifacts stored in SQL and NoSQL databases to a neat, well-organized dataset. It covers text mining, machine learning, and network analysis; processing numeric data with the NumPy and Pandas modules; and describing and analyzing data using statistical and network-theoretical methods. It has actual examples of data analysis at work, as well as mini-projects for you to enjoy. \n",
      "\n",
      "  The second book shows how, starting with simple networks, one can convert real-life and synthetic network graphs into Networkx data structures. The reader will look at more sophisticated networks and learn more powerful machinery to handle centrality calculation, blockmodeling, and clique and community detection. Get familiar with presentation-quality network visualization tools, both programmable and interactive--such as Gephi, a CNA explorer. The reader will  adapt the patterns from the case studies to your problems, explore big networks with NetworKit, a high-performance networkx substitute. Each part in the book gives an overview of a class of networks, includes a practical study of networkx functions and techniques, and concludes with case studies from various fields, including social networking, anthropology, marketing, and sports analytics.\n",
      "\n",
      "  \n",
      "The books are available for purchase at the publisher's site, and on Amazon (DZPYDS, DZCNAPY).\n",
      "\n",
      "Presentations\n",
      "\n",
      "Networks of Music Groups as Success Predictors - Social networks, digital humanities\n",
      "Network Science Workshop - General networks\n",
      "Resilience in Transaction-Oriented Networks - Communication networks\n",
      "Peer Ratings in Massive Online Social Networks - Social networks\n",
      "Semantic Networks of Interests in Online NSSI Communities - Semantic networks\n",
      "Towards an Ideal Store - Product networks\n",
      "\n",
      "Publications\n",
      "\n",
      "D.Zinoviev, \"Analyzing Cultural Domains with Python,\" PragPub, 82, pp. 26-33, Apr 2016\n",
      "D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\" Digital Health, doi:10.1177/2055207616642118, SAGE, Apr 2016\n",
      "D.Zinoviev, \"The Pain of Complexity,\", Leonardo, 2016\n",
      "D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\" in Studies in Computational Intelligence, vol. 597, pp. 179-190, Springer, Mar 2015\n",
      "D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Mitigation of delayed management costs in transaction-oriented systems,\" Sep 2014\n",
      "D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Simulating resilience in transaction-oriented networks,\" in Proc. Spring Simulation Multi-Conference, (San Diego, CA), Apr. 2013\n",
      "D.Zinoviev, D.Stefanescu, L.Swenson, and G.Fireman, \"Semantic networks of interests in online NSSI communities,\" in Proc. Workshop \"Words and Networks\" (Evanston, IL), June 2012\n",
      "D.Zinoviev and S.Llewelyn, \"Co-Evolution of Friendship and Publishing in Online Blogging Social Networks,\" WebSci-2012 (poster)\n",
      "D.Zinoviev, \"Information diffusion in social networks,\" in Social Networking and Community Behavior Modeling: Qualitative and Quantitative Measures (M. Safar, ed.), Hershey, PA: IGI Global, Dec. 2011\n",
      "D.Zinoviev and V.Duong, \"A game theoretical approach to broadcast  information diffusion in social networks,\" 6. in Proc. 44th Annual Simulation Symp., (Boston, MA), pp. 47-52, Apr. 2011\n",
      "D.Zinoviev and V.Duong, \"A game theoretical approach to modeling full-duplex information dissemination,\" in Proc. Summer Simulation Multi-Conference, (Ottawa, Canada), pp. 358-363, July 2010\n",
      "D.Zinoviev, V.Duong, and H.Zhang, \"A game theoretical approach to modeling information dissemination in social networks,\" in Proc. Int. Multi-Conference on Complexity, Informatics and Cybernetics, vol. I, pp. 407-412, IIIS, Apr. 2010\n",
      "D.Zinoviev and V.Duong, \"Toward Understanding Friendship in Online Social Networks,\" The Intl J. of Technology, Knowledge, and Society, pp. 1-8, May 2009\n",
      "D.Zinoviev, \"Topology and Geometry of Online Social Networks,\" in Proc. 12th World Multi-Conference on Systemics, Cybernetics and Informatics, vol. VI, pp. 138-143, 2008\n",
      "\n",
      "Other Projects\n",
      "\n",
      "Vixi: The Game of Meaning, produced in collaboration with Evgenia Cherkasova from Philosophy Department.\n",
      "All Characters from War and Peace by L.Tolstoy\n",
      "Mapping the Bible: Social Networks in the Holy Book. A book of graphs.\n",
      "FIFA World Cup 2014: Who Beat Whom?\n",
      "The seed post \"9 American habits I lost when I moved to Germany\" and its 125 \"likes\" and \"shares\" on Facebook. Nodes represent Facebook users, node sizes - number of friends/followers. Two nodes are connected if they are friends/followers and both reacted to the seed post. Red nodes denote shares. The post was originally published at the yellow node.\n",
      "\n",
      "Contacts\n",
      "\n",
      "Email\n",
      "Suffolk University\n",
      "Google Scholar\n",
      "LinkedIn\n",
      "Academia.edu\n",
      "ResearchGate\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "url=\"http://www.networksciencelab.com\"\n",
    "soup1=BeautifulSoup(urlopen(url))\n",
    "print(soup1.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.661016949152543\n",
      "43.27973735299687\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import statistics\n",
    "with open(\"DataScience_code/예제파일/Demographic_Statistics_By_Zip_Code.csv\") as file:\n",
    "    data=list(csv.reader(file))\n",
    "    part_index=data[0].index('COUNT PARTICIPANTS')\n",
    "    part_list=[int(row[part_index])for row in data[1:]]\n",
    "    part_list2=[]\n",
    "    for row in data[1:]:\n",
    "        part_list2.append(int(row[part_index]))\n",
    "print(statistics.mean(part_list))\n",
    "print(statistics.stdev(part_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cat.n.01'),\n",
       " Synset('guy.n.01'),\n",
       " Synset('cat.n.03'),\n",
       " Synset('kat.n.01'),\n",
       " Synset('cat-o'-nine-tails.n.01'),\n",
       " Synset('caterpillar.n.02'),\n",
       " Synset('big_cat.n.01'),\n",
       " Synset('computerized_tomography.n.01'),\n",
       " Synset('cat.v.01'),\n",
       " Synset('vomit.v.01')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "wn=nltk.corpus.wordnet\n",
    "wn.synsets(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=wn.synset(\"cat.n.01\")\n",
    "y=wn.synset(\"lynx.n.01\")\n",
    "x.path_similarity(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, Synset('guy.n.01'), Synset('dog.n.03'))\n",
      "['an informal term for a youth or man', 'informal term for a man']\n"
     ]
    }
   ],
   "source": [
    "list1=[]\n",
    "for x in wn.synsets('cat'):\n",
    "    for y in wn.synsets('dog'):\n",
    "        if x.path_similarity(y):\n",
    "            list1.append((x.path_similarity(y),x,y))\n",
    "print(max(list1))\n",
    "print([symxy.definition()for symxy in max(list1)[1:]])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'little', 'network', 'science', 'lab', 'my', 'little', 'network', 'science', 'lab', 'by', 'dmitry', 'zinoviev', 'books', 'i', 'am', 'excited', 'to', 'announce', 'my', 'books', ',', '``', 'data', 'science', 'essentials', 'in', 'python', '.', 'collect', '→', 'organize', '→', 'explore', '→', 'predict', '→', 'value', \"''\", '(', 'a.k.a', '.', 'dzpyds', ')', 'and', '``', 'complex', 'network', 'analysis', 'in', 'python', '.', 'recognize', '→', 'construct', '→', 'visualize', '→', 'analyze', '→', 'interpret', \"''\", '(', 'a.k.a', '.', 'dzcnapy', ')', ',', 'published', 'by', 'the', 'pragmatic', 'bookshelf', '.', 'the', 'first', 'book', 'is', 'intended', 'for', 'seasoned', 'data', 'scientists', 'and', 'statisticians', 'migrating', 'from', 'r', 'to', 'python', ',', 'as', 'well', 'as', 'for', 'beginners', 'willing', 'to', 'learn', 'elements', 'of', 'data', 'science', 'in', 'python', '.', 'the', 'book', 'leads', 'you', 'from', 'messy', ',', 'unstructured', 'artifacts', 'stored', 'in', 'sql', 'and', 'nosql', 'databases', 'to', 'a', 'neat', ',', 'well-organized', 'dataset', '.', 'it', 'covers', 'text', 'mining', ',', 'machine', 'learning', ',', 'and', 'network', 'analysis', ';', 'processing', 'numeric', 'data', 'with', 'the', 'numpy', 'and', 'pandas', 'modules', ';', 'and', 'describing', 'and', 'analyzing', 'data', 'using', 'statistical', 'and', 'network-theoretical', 'methods', '.', 'it', 'has', 'actual', 'examples', 'of', 'data', 'analysis', 'at', 'work', ',', 'as', 'well', 'as', 'mini-projects', 'for', 'you', 'to', 'enjoy', '.', 'the', 'second', 'book', 'shows', 'how', ',', 'starting', 'with', 'simple', 'networks', ',', 'one', 'can', 'convert', 'real-life', 'and', 'synthetic', 'network', 'graphs', 'into', 'networkx', 'data', 'structures', '.', 'the', 'reader', 'will', 'look', 'at', 'more', 'sophisticated', 'networks', 'and', 'learn', 'more', 'powerful', 'machinery', 'to', 'handle', 'centrality', 'calculation', ',', 'blockmodeling', ',', 'and', 'clique', 'and', 'community', 'detection', '.', 'get', 'familiar', 'with', 'presentation-quality', 'network', 'visualization', 'tools', ',', 'both', 'programmable', 'and', 'interactive', '--', 'such', 'as', 'gephi', ',', 'a', 'cna', 'explorer', '.', 'the', 'reader', 'will', 'adapt', 'the', 'patterns', 'from', 'the', 'case', 'studies', 'to', 'your', 'problems', ',', 'explore', 'big', 'networks', 'with', 'networkit', ',', 'a', 'high-performance', 'networkx', 'substitute', '.', 'each', 'part', 'in', 'the', 'book', 'gives', 'an', 'overview', 'of', 'a', 'class', 'of', 'networks', ',', 'includes', 'a', 'practical', 'study', 'of', 'networkx', 'functions', 'and', 'techniques', ',', 'and', 'concludes', 'with', 'case', 'studies', 'from', 'various', 'fields', ',', 'including', 'social', 'networking', ',', 'anthropology', ',', 'marketing', ',', 'and', 'sports', 'analytics', '.', 'the', 'books', 'are', 'available', 'for', 'purchase', 'at', 'the', 'publisher', \"'s\", 'site', ',', 'and', 'on', 'amazon', '(', 'dzpyds', ',', 'dzcnapy', ')', '.', 'presentations', 'networks', 'of', 'music', 'groups', 'as', 'success', 'predictors', '-', 'social', 'networks', ',', 'digital', 'humanities', 'network', 'science', 'workshop', '-', 'general', 'networks', 'resilience', 'in', 'transaction-oriented', 'networks', '-', 'communication', 'networks', 'peer', 'ratings', 'in', 'massive', 'online', 'social', 'networks', '-', 'social', 'networks', 'semantic', 'networks', 'of', 'interests', 'in', 'online', 'nssi', 'communities', '-', 'semantic', 'networks', 'towards', 'an', 'ideal', 'store', '-', 'product', 'networks', 'publications', 'd.zinoviev', ',', '``', 'analyzing', 'cultural', 'domains', 'with', 'python', ',', \"''\", 'pragpub', ',', '82', ',', 'pp', '.', '26-33', ',', 'apr', '2016', 'd.', 'zinoviev', ',', 'd.', 'stefanescu', ',', 'g.', 'fireman', ',', 'and', 'l.', 'swenson', ',', '``', 'semantic', 'networks', 'of', 'interests', 'in', 'online', 'non-suicidal', 'self-injury', 'communities', ',', \"''\", 'digital', 'health', ',', 'doi:10.1177/2055207616642118', ',', 'sage', ',', 'apr', '2016', 'd.zinoviev', ',', '``', 'the', 'pain', 'of', 'complexity', ',', \"''\", ',', 'leonardo', ',', '2016', 'd.zinoviev', ',', 'z.zhu', ',', 'and', 'k.li', ',', '``', 'building', 'mini-categories', 'in', 'product', 'networks', ',', \"''\", 'in', 'studies', 'in', 'computational', 'intelligence', ',', 'vol', '.', '597', ',', 'pp', '.', '179-190', ',', 'springer', ',', 'mar', '2015', 'd.zinoviev', ',', 'h.benbrahim', ',', 'g.meszoely', ',', 'and', 'd.stefanescu', ',', '``', 'mitigation', 'of', 'delayed', 'management', 'costs', 'in', 'transaction-oriented', 'systems', ',', \"''\", 'sep', '2014', 'd.zinoviev', ',', 'h.benbrahim', ',', 'g.meszoely', ',', 'and', 'd.stefanescu', ',', '``', 'simulating', 'resilience', 'in', 'transaction-oriented', 'networks', ',', \"''\", 'in', 'proc', '.', 'spring', 'simulation', 'multi-conference', ',', '(', 'san', 'diego', ',', 'ca', ')', ',', 'apr', '.', '2013', 'd.zinoviev', ',', 'd.stefanescu', ',', 'l.swenson', ',', 'and', 'g.fireman', ',', '``', 'semantic', 'networks', 'of', 'interests', 'in', 'online', 'nssi', 'communities', ',', \"''\", 'in', 'proc', '.', 'workshop', '``', 'words', 'and', 'networks', \"''\", '(', 'evanston', ',', 'il', ')', ',', 'june', '2012', 'd.zinoviev', 'and', 's.llewelyn', ',', '``', 'co-evolution', 'of', 'friendship', 'and', 'publishing', 'in', 'online', 'blogging', 'social', 'networks', ',', \"''\", 'websci-2012', '(', 'poster', ')', 'd.zinoviev', ',', '``', 'information', 'diffusion', 'in', 'social', 'networks', ',', \"''\", 'in', 'social', 'networking', 'and', 'community', 'behavior', 'modeling', ':', 'qualitative', 'and', 'quantitative', 'measures', '(', 'm.', 'safar', ',', 'ed', '.', ')', ',', 'hershey', ',', 'pa', ':', 'igi', 'global', ',', 'dec.', '2011', 'd.zinoviev', 'and', 'v.duong', ',', '``', 'a', 'game', 'theoretical', 'approach', 'to', 'broadcast', 'information', 'diffusion', 'in', 'social', 'networks', ',', \"''\", '6.', 'in', 'proc', '.', '44th', 'annual', 'simulation', 'symp.', ',', '(', 'boston', ',', 'ma', ')', ',', 'pp', '.', '47-52', ',', 'apr', '.', '2011', 'd.zinoviev', 'and', 'v.duong', ',', '``', 'a', 'game', 'theoretical', 'approach', 'to', 'modeling', 'full-duplex', 'information', 'dissemination', ',', \"''\", 'in', 'proc', '.', 'summer', 'simulation', 'multi-conference', ',', '(', 'ottawa', ',', 'canada', ')', ',', 'pp', '.', '358-363', ',', 'july', '2010', 'd.zinoviev', ',', 'v.duong', ',', 'and', 'h.zhang', ',', '``', 'a', 'game', 'theoretical', 'approach', 'to', 'modeling', 'information', 'dissemination', 'in', 'social', 'networks', ',', \"''\", 'in', 'proc', '.', 'int', '.', 'multi-conference', 'on', 'complexity', ',', 'informatics', 'and', 'cybernetics', ',', 'vol', '.', 'i', ',', 'pp', '.', '407-412', ',', 'iiis', ',', 'apr', '.', '2010', 'd.zinoviev', 'and', 'v.duong', ',', '``', 'toward', 'understanding', 'friendship', 'in', 'online', 'social', 'networks', ',', \"''\", 'the', 'intl', 'j.', 'of', 'technology', ',', 'knowledge', ',', 'and', 'society', ',', 'pp', '.', '1-8', ',', 'may', '2009', 'd.zinoviev', ',', '``', 'topology', 'and', 'geometry', 'of', 'online', 'social', 'networks', ',', \"''\", 'in', 'proc', '.', '12th', 'world', 'multi-conference', 'on', 'systemics', ',', 'cybernetics', 'and', 'informatics', ',', 'vol', '.', 'vi', ',', 'pp', '.', '138-143', ',', '2008', 'other', 'projects', 'vixi', ':', 'the', 'game', 'of', 'meaning', ',', 'produced', 'in', 'collaboration', 'with', 'evgenia', 'cherkasova', 'from', 'philosophy', 'department', '.', 'all', 'characters', 'from', 'war', 'and', 'peace', 'by', 'l.tolstoy', 'mapping', 'the', 'bible', ':', 'social', 'networks', 'in', 'the', 'holy', 'book', '.', 'a', 'book', 'of', 'graphs', '.', 'fifa', 'world', 'cup', '2014', ':', 'who', 'beat', 'whom', '?', 'the', 'seed', 'post', '``', '9', 'american', 'habits', 'i', 'lost', 'when', 'i', 'moved', 'to', 'germany', \"''\", 'and', 'its', '125', '``', 'likes', \"''\", 'and', '``', 'shares', \"''\", 'on', 'facebook', '.', 'nodes', 'represent', 'facebook', 'users', ',', 'node', 'sizes', '-', 'number', 'of', 'friends/followers', '.', 'two', 'nodes', 'are', 'connected', 'if', 'they', 'are', 'friends/followers', 'and', 'both', 'reacted', 'to', 'the', 'seed', 'post', '.', 'red', 'nodes', 'denote', 'shares', '.', 'the', 'post', 'was', 'originally', 'published', 'at', 'the', 'yellow', 'node', '.', 'contacts', 'email', 'suffolk', 'university', 'google', 'scholar', 'linkedin', 'academia.edu', 'researchgate']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import LancasterStemmer\n",
    "Is=LancasterStemmer()\n",
    "url=\"http://www.networksciencelab.com\"\n",
    "soup=BeautifulSoup(urlopen(url))\n",
    "words=nltk.word_tokenize(soup.text)\n",
    "words=[w.lower() for w in words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('network', 35), ('soc', 12), ('book', 9), ('dat', 7), ('analys', 7), ('onlin', 7), ('pp', 7), ('sci', 6), ('commun', 6), ('proc', 6)]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import LancasterStemmer\n",
    "Is=LancasterStemmer()\n",
    "url=\"http://www.networksciencelab.com\"\n",
    "soup=BeautifulSoup(urlopen(url))\n",
    "words=nltk.word_tokenize(soup.text)\n",
    "words=[w.lower() for w in words]\n",
    "words1=[]\n",
    "for w in words:\n",
    "    if w not in stopwords.words(\"english\") and w.isalnum():\n",
    "        words1.append(Is.stem(w))\n",
    "\n",
    "print(Counter(words1).most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. Data science is related to data mining, machine learning and big data.\n",
      "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\n",
      "\n",
      "\n",
      "== Foundations ==\n",
      "Data science is an interdisciplinary field focused on extracting knowledge from data sets, which are typically large (see big data), and applying the knowledge and actionable insights from data to solve problems in a wide range of application domains. The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, information visualization, data integration, graphic design, complex systems, communication and business. Statistician Nathan Yau, drawing on Ben Fry, also links data science to human-computer interaction: users should be able to intuitively control and explore data. In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.\n",
      "\n",
      "\n",
      "=== Relationship to statistics ===\n",
      "Many statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics. Others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data. Vasant Dhar writes that statistics emphasizes quantitative data and description. In contrast, data science deals with quantitative and qualitative data (e.g. images) and emphasizes prediction and action. Andrew Gelman of Columbia University and data scientist Vincent Granville have described statistics as a nonessential part of data science.\n",
      "Stanford professor David Donoho writes that data science is not distinguished from statistics by the size of datasets or use of computing, and that many graduate programs misleadingly advertise their analytics and statistics training as the essence of a data science program. He describes data science as an applied field growing out of traditional statistics. \n",
      "In summary, data science can be therefore described as an applied branch of statistics.\n",
      "\n",
      "\n",
      "== Etymology ==\n",
      "\n",
      "\n",
      "=== Early usage ===\n",
      "In 1962, John Tukey described a field he called “data analysis,” which resembles modern data science. In 1985, in a lecture given to the Chinese Academy of Sciences in Beijing, C.F. Jeff Wu used the term Data Science for the first time as an alternative name for statistics. Later, attendees at a 1992 statistics symposium at the University of Montpellier II acknowledged the emergence of a new discipline focused on data of various origins and forms, combining established concepts and principles of statistics and data analysis with computing.The term “data science” has been traced back to 1974, when Peter Naur proposed it as an alternative name for computer science. In 1996, the International Federation of Classification Societies became the first conference to specifically feature data science as a topic. However, the definition was still in flux. After the 1985 lecture in the Chinese Academy of Sciences in Beijing, in 1997 C.F. Jeff Wu again suggested that statistics should be renamed data science. He reasoned that a new name would help statistics shed inaccurate stereotypes, such as being synonymous with accounting, or limited to describing data. In 1998, Hayashi Chikio argued for data science as a new, interdisciplinary concept, with three aspects: data design, collection, and analysis.During the 1990s, popular terms for the process of finding patterns in datasets (which were increasingly large) included “knowledge discovery” and “data mining”.\n",
      "\n",
      "\n",
      "=== Modern usage ===\n",
      "The modern conception of data science as an independent discipline is sometimes attributed to William S. Cleveland. In a 2001 paper, he advocated an expansion of statistics beyond theory into technical areas; because this would significantly change the field, it warranted a new name. \"Data science\" became more widely used in the next few years: in 2002, the Committee on Data for Science and Technology launched Data Science Journal. In 2003, Columbia University launched The Journal of Data Science. In 2014, the American Statistical Association's Section on Statistical Learning and Data Mining changed its name to the Section on Statistical Learning and Data Science, reflecting the ascendant popularity of data science.The professional title of “data scientist” has been attributed to DJ Patil and Jeff Hammerbacher in 2008. Though it was used by the National Science Board in their 2005 report, \"Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century,\" it referred broadly to any key role in managing a digital data collection.There is still no consensus on the definition of data science and it is considered by some to be a buzzword.\n",
      "\n",
      "\n",
      "== Impact ==\n",
      "Big data is very quickly becoming a vital tool for businesses and companies of all sizes. The availability and interpretation of big data has altered the business models of old industries and enabled the creation of new ones. Data-driven businesses are worth $1.2 trillion collectively in 2020, an increase from $333 billion in the year 2015. Data scientists are responsible for breaking down big data into usable information and creating software and algorithms that help companies and organizations determine optimal operations. As big data continues to have a major impact on the world, data science does as well due to the close relationship between the two.\n",
      "\n",
      "\n",
      "== Technologies and techniques ==\n",
      "There are a variety of different technologies and techniques that are used for data science which depend on the application. More recently, full-featured, end-to-end platforms have been developed and heavily used for data science and machine learning.\n",
      "\n",
      "\n",
      "=== Techniques ===\n",
      "\n",
      "Linear Regression\n",
      "Logistic Regression\n",
      "Decision tree is used as prediction models for classification and data fitting. The decision tree structure can be used to generate rules able to classify or predict target/class/label variable based on the observation attributes.\n",
      "Support Vector Machine (SVM)\n",
      "Clustering is a technique used to group data together.\n",
      "Dimensionality reduction is used to reduce the complexity of data computation so that it can be performed more quickly.\n",
      "Machine learning is a technique used to perform tasks by inferencing patterns from data\n",
      "\n",
      "\n",
      "== References ==\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "page=wikipedia.page(\"Data_science\")\n",
    "print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dat', 70), ('sci', 48), ('stat', 25), ('us', 17), ('field', 8)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "import wikipedia\n",
    "ls=PorterStemmer()\n",
    "page=wikipedia.page(\"Data_science\")\n",
    "\n",
    "\n",
    "words=nltk.word_tokenize(page.content)\n",
    "words=[w.lower() for w in words]\n",
    "words1=[]\n",
    "for w in words:\n",
    "    if w not in stopwords.words(\"english\") and w.isalnum():\n",
    "        words1.append(Is.stem(w))\n",
    "\n",
    "print(Counter(words1).most_common(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
